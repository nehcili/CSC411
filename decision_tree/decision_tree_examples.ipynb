{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "## 1. Implementation - using gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group is a iterator of np.array of integers, where each integer represents a class type\n",
    "# gini_indx: np.array --> float\n",
    "\n",
    "def gini_index(groups):\n",
    "    # count all samples at split point\n",
    "    n_instances = sum([len(group) for group in groups])\n",
    "    \n",
    "    # sum weighted Gini index for each group\n",
    "    gini = 1.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        # avoid divide by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "\n",
    "        # score the group based on the score for each class\n",
    "        unique, counts = np.unique(group, return_counts=True)\n",
    "        #print(counts)\n",
    "        score = np.sum((counts / size) ** 2)\n",
    " \n",
    "        # weight the group score by its relative size\n",
    "        gini -= score * (size / n_instances)\n",
    "        \n",
    "    return gini\n",
    " \n",
    "# test Gini values\n",
    "# print(gini_index(np.array([[1, 0], [1, 0, 1]])))\n",
    "# print(gini_index(np.array([[0, 0], [1, 1, 1]])))\n",
    "\n",
    "def try_split(index, value, data):\n",
    "    feature = data[:, index]\n",
    "    \n",
    "    left_index = np.where(feature < value)[0]\n",
    "    right_index = np.where(feature >= value)[0]\n",
    "    \n",
    "    return left_index, right_index       \n",
    "\n",
    "def get_binary_split(data, labels):\n",
    "    b_index, b_gini, b_value, b_left, b_right = np.nan, 1, np.nan, None, None\n",
    "    \n",
    "    num_features = len(data[0])\n",
    "    \n",
    "    for index in range(0, num_features):\n",
    "        for row in data:\n",
    "            left_index, right_index = try_split(index, row[index], data)\n",
    "            gini = gini_index([labels[left_index], labels[right_index]])\n",
    "            \n",
    "            if gini < b_gini:\n",
    "                b_index, b_gini, b_value, b_left, b_right = index, gini, row[index], left_index, right_index\n",
    "    \n",
    "    return {'gini': b_gini, 'index':b_index, 'value':b_value, 'left':b_left, 'right':b_right}  \n",
    "\n",
    "class DecisionTree(object):\n",
    "    \n",
    "    def __init__(self, depth=1):\n",
    "        self.depth = depth\n",
    "        self.node = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    def most_freq(self, arr):\n",
    "        unique, counts = np.unique(arr, return_counts=True)\n",
    "        ind = np.argmax(counts)\n",
    "        return unique[ind]\n",
    "    \n",
    "    # data is an np.array of size N times D\n",
    "    # N = number of samples\n",
    "    # D = number of features\n",
    "    # labels is an np.array of size N times 1\n",
    "    def train(self, data, labels):\n",
    "        if self.depth == 0:\n",
    "            self.node = (self.most_freq(labels), 0, None, None)\n",
    "        else:\n",
    "            splited_data = get_binary_split(data, labels)\n",
    "            \n",
    "            #print(len(splited_data['left']))\n",
    "            #print(len(splited_data['right']))\n",
    "            \n",
    "            if (len(splited_data['left']) == 0) or (len(splited_data['right']) ==0):\n",
    "                self.depth = 0\n",
    "                self.node = (self.most_freq(labels), 0, None, None)\n",
    "            else:\n",
    "                self.node = (None, splited_data['gini'], splited_data['index'], splited_data['value'])\n",
    "                self.left = DecisionTree(self.depth-1)\n",
    "                self.left.train(data[splited_data['left']], labels[splited_data['left']])\n",
    "                \n",
    "                self.right = DecisionTree(self.depth-1)\n",
    "                self.right.train(data[splited_data['right']], labels[splited_data['right']])  \n",
    "                \n",
    "                \n",
    "        \n",
    "                \n",
    "\n",
    "    # row is a np.array of size D\n",
    "    def predict_single(self, row):\n",
    "        if self.depth == 0:\n",
    "            return self.node[0]\n",
    "        else:\n",
    "            index = self.node[2]\n",
    "            value = self.node[-1]\n",
    "\n",
    "            if row[index] < value:\n",
    "                return self.left.predict_single(row)\n",
    "            else:\n",
    "                return self.right.predict_single(row)\n",
    "                    \n",
    "    def predict(self, X):\n",
    "        ypred = []\n",
    "        \n",
    "        for row in X:\n",
    "            ypred.append(self.predict_single(row))\n",
    "        \n",
    "        return ypred\n",
    "    \n",
    "    def show_structure(self, max_depth=-1):\n",
    "        if max_depth == -1:\n",
    "            max_depth = self.depth\n",
    "            \n",
    "        if self.depth > 0:\n",
    "            tabs = '\\t' * (max_depth-self.depth)\n",
    "            m = '{}[Depth {}: index={}, value={}, gini={}]'.format(tabs,\n",
    "                                                                   max_depth-self.depth+1, \n",
    "                                                                   self.node[2],\n",
    "                                                                   self.node[3],\n",
    "                                                                   round(self.node[1],3))\n",
    "            print(m)\n",
    "            if self.left != None:\n",
    "                self.left.show_structure(max_depth)\n",
    "            if self.right != None:\n",
    "                self.right.show_structure(max_depth)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Notes\n",
    "Deciding if a bank note is fradulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# data is first downloweded into DATA_PATH from \n",
    "# http://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\n",
    "import os\n",
    "\n",
    "DATA_PATH = 'banknote'\n",
    "FILE_NAME = 'data_banknote_authentication.txt'\n",
    "\n",
    "def load_data(data_path=DATA_PATH, file_name=FILE_NAME):\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    return data.values[:, :-1], data.values[:,-1]\n",
    "\n",
    "DATA, LABELS = load_data()\n",
    "LABELS = LABELS * 1.0\n",
    "\n",
    "train_set = DATA[:1234, :]\n",
    "train_labels = LABELS[:1234]\n",
    "\n",
    "test_set = DATA[1234:,:]\n",
    "test_labels = LABELS[1234:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_auth = DecisionTree(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_auth.train(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0364963503649635"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = bank_auth.predict(test_set)\n",
    "e = len(test_labels[test_labels != ypred])/len(test_labels)\n",
    "e # error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Depth 1: index=0, value=0.3223, gini=0.246]\n",
      "\t[Depth 2: index=1, value=5.8974, gini=0.182]\n",
      "\t\t[Depth 3: index=2, value=6.2204, gini=0.108]\n",
      "\t\t\t[Depth 4: index=1, value=4.1158, gini=0.014]\n",
      "\t\t\t[Depth 4: index=1, value=-4.6062, gini=0.016]\n",
      "\t\t[Depth 3: index=0, value=-2.7419, gini=0.015]\n",
      "\t\t\t[Depth 4: index=2, value=3.1392, gini=0.0]\n",
      "\t\t\t[Depth 4: index=0, value=-1.8584, gini=-0.0]\n",
      "\t[Depth 2: index=2, value=-4.3839, gini=0.118]\n",
      "\t\t[Depth 3: index=0, value=4.2164, gini=0.0]\n",
      "\t\t\t[Depth 4: index=0, value=0.64376, gini=-0.0]\n",
      "\t\t\t[Depth 4: index=0, value=5.7456, gini=-0.0]\n",
      "\t\t[Depth 3: index=0, value=1.594, gini=0.09]\n",
      "\t\t\t[Depth 4: index=2, value=-2.2718, gini=0.175]\n",
      "\t\t\t[Depth 4: index=0, value=2.0421, gini=0.012]\n"
     ]
    }
   ],
   "source": [
    "bank_auth.show_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris\n",
    "\n",
    "Classification of types of iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "def prep_train_test(rate=0.9):\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    ind = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        ind.append(np.random.choice(50, int(50*rate), replace=False) + 50*i)\n",
    "    \n",
    "    train_ind = np.concatenate(ind)\n",
    "    test_ind = np.setdiff1d(np.arange(150), train_ind)\n",
    "        \n",
    "    \n",
    "    return X[train_ind], y[train_ind], X[test_ind], y[test_ind]\n",
    "\n",
    "iris_train_data, iris_train_labels, iris_test_data,iris_test_labels = prep_train_test(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Depth 1: index=2, value=3.0, gini=0.333]\n",
      "\t[Depth 2: index=1, value=3.3, gini=-0.0]\n",
      "\t\t[Depth 3: index=0, value=4.8, gini=0.0]\n",
      "\t\t[Depth 3: index=1, value=3.6, gini=-0.0]\n",
      "\t[Depth 2: index=2, value=4.8, gini=0.103]\n",
      "\t\t[Depth 3: index=3, value=1.7, gini=0.0]\n",
      "\t\t[Depth 3: index=3, value=1.8, gini=0.103]\n"
     ]
    }
   ],
   "source": [
    "iris_clf = DecisionTree(3)\n",
    "iris_clf.train(iris_train_data, iris_train_labels)\n",
    "iris_clf.show_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06666666666666667"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = iris_clf.predict(iris_test_data)\n",
    "e = len(iris_test_labels[iris_test_labels != ypred])/len(iris_test_labels)\n",
    "e # error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
