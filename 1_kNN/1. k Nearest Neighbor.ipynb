{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. k Nearest Neighbor\n",
    "\n",
    "## 1.1 Size of k vs n\n",
    "Pros and Cons of size of k:\n",
    "- Small k\n",
    "    - Good at capturing fine-grained patterns\n",
    "    - may overfit\n",
    "- Large k\n",
    "    - Smoothed/average stable prediction\n",
    "    - may underfit\n",
    "- Rule: $k < \\sqrt{n}$ where $n$ is the number of training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Essentials\n",
    "\n",
    "- We note that kNN does not learn! The classification/regression is run at test time\n",
    "- Curse of dimensionality. Let the input dimention be $d$ and the test sample size be $N$. Then each computation for an input consists of $O(dN)$ operators. Sorting costs $N \\log(N)$ after computing the minimum distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 A simple implementation\n",
    "http://cs231n.github.io/classification/#nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Neighbor implementation\n",
    "# 1 NN\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class NearestNeighbor(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, X, y): \n",
    "        self.Xtr = X # X is N times D\n",
    "        self.ytr = y # y is N times 1\n",
    "    \n",
    "    def predict(self, X): # X is M times D, each row needs a prediction\n",
    "        num_test = X.shape[0]\n",
    "        \n",
    "        ypred = np.empty(num_test, dtype=self.ytr.dtype) # initialize ypred to store the prediction\n",
    "        \n",
    "        for i in range(num_test):\n",
    "            distance = np.sum(np.square(Xtr-X[i,:]), axis=1)\n",
    "            ypred[i] = self.ytr[np.argmin(distance)] # find the closest one\n",
    "        \n",
    "        return ypred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000981\n"
     ]
    }
   ],
   "source": [
    "# Simple example\n",
    "e = 0 # initialize error to 0 for the test\n",
    "\n",
    "# do 100 tests\n",
    "for i in range(100):\n",
    "    nn = NearestNeighbor()\n",
    "    \n",
    "    # test case:\n",
    "    # random uniform distribution on (0,1)\n",
    "    # label = 1 if the random number x is 0.2 < x < 0.5.\n",
    "    # label = 0 otherwise\n",
    "    Xtr = np.random.random(1000) \n",
    "    ytr = (1*(Xtr < 0.5)) * (1*(0.2 < Xtr))\n",
    "\n",
    "    nn.train(Xtr, ytr)\n",
    "\n",
    "    X = np.random.random(20000)\n",
    "    y = (1*(X < 0.5)) * (1 *(0.2 < X))\n",
    "\n",
    "    Xtr= Xtr[:, np.newaxis]\n",
    "    X = X[:, np.newaxis]\n",
    "\n",
    "    ypred = nn.predict(X)\n",
    "    e += len(ypred[ypred != y])/len(y) # number of wrong classifications\n",
    "    \n",
    "print(e/100) # print the error averaged over 100 tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Neighbor implementation\n",
    "# k NN\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class kNN(object):\n",
    "    \n",
    "    def __init__(self, k=1): # k is assumed to be 1 if omiited\n",
    "        self.k = k\n",
    "    \n",
    "    def train(self, X, y): \n",
    "        self.Xtr = X # X is N times D\n",
    "        self.ytr = y # y is N times 1\n",
    "    \n",
    "    def predict(self, X): # X is M times D, each row needs a prediction\n",
    "        num_test = X.shape[0]\n",
    "        \n",
    "        ypred = np.empty(num_test, dtype=self.ytr.dtype)\n",
    "        \n",
    "        for i in range(num_test):\n",
    "            distance = np.sum(np.square(self.Xtr-X[i,:]), axis=1)\n",
    "            idx = np.argpartition(distance, self.k)[:self.k]      \n",
    "            ypred[i] = np.mean(self.ytr[idx])\n",
    "        \n",
    "        return ypred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013764\n"
     ]
    }
   ],
   "source": [
    "# Simple example\n",
    "e = 0\n",
    "\n",
    "for i in range(100):\n",
    "    nn = kNN(15)\n",
    "    Xtr = np.random.random(1000)\n",
    "    ytr = (1*(Xtr < 0.5)) * (1*(0.2 < Xtr))\n",
    "\n",
    "    nn.train(Xtr, ytr)\n",
    "\n",
    "    X = np.random.random(20000)\n",
    "    y = (1*(X < 0.5)) * (1 *(0.2 < X))\n",
    "\n",
    "    Xtr= Xtr[:, np.newaxis]\n",
    "    X = X[:, np.newaxis]\n",
    "\n",
    "    ypred = nn.predict(X)\n",
    "    e += len(ypred[ypred != y])/len(y) # error\n",
    "    \n",
    "print(e/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
